{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-ae5810db-f20e-4b14-96e8-9b4daf8adc8a","output_cleared":false,"source_hash":"4b852cb6","execution_millis":17658,"execution_start":1604441017072},"source":"# Start writing code here...\n\n# Wisoo\n\n%run \"./calibrateCamera.ipynb\"","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting pupil-apriltags\n  Downloading pupil_apriltags-1.0.4-cp37-cp37m-manylinux2010_x86_64.whl (7.0 MB)\n\u001b[K     |████████████████████████████████| 7.0 MB 28.8 MB/s \n\u001b[?25hRequirement already satisfied: numpy in /opt/venv/lib/python3.7/site-packages (from pupil-apriltags) (1.19.2)\nInstalling collected packages: pupil-apriltags\nSuccessfully installed pupil-apriltags-1.0.4\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nCollecting opencv-python\n  Downloading opencv_python-4.4.0.46-cp37-cp37m-manylinux2014_x86_64.whl (49.5 MB)\n\u001b[K     |████████████████████████████████| 49.5 MB 266 kB/s \n\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /opt/venv/lib/python3.7/site-packages (from opencv-python) (1.19.2)\nInstalling collected packages: opencv-python\nSuccessfully installed opencv-python-4.4.0.46\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n./calibrateCamera.ipynb:92: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n./calibrateCamera.ipynb:93: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Input:   \nCamera calibration: calMatrix and distCoeffs.  \n(outputs from calibrateCamera().   \nImage of the two AprilBoards setup with object to be scanned.   \nES 143 AprilBoard datafile (AprilBoards.pickle).   \nOutput:  \nplane_h, plane_v -- Two homogeneous 4-vectors corresponding to planes (\\Pi_v, \\Pi_h) in the camera-centered coordinate system.  ","metadata":{"tags":[],"cell_id":"00001-5c374fef-b2a9-49d0-a894-1d1894b97371"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-b471fb41-e589-404f-b802-ab271b7c7038","output_cleared":false,"source_hash":"5d051386","execution_millis":18736,"execution_start":1604441037360},"source":"!pip install av\n!pip install pims\n!pip install pillow\n!pip install plotly\nimport av\nimport pims\nfrom PIL import Image\nimport plotly.express as px\nimport plotly.graph_objects as go\n","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting av\n  Downloading av-8.0.2-cp37-cp37m-manylinux2010_x86_64.whl (36.9 MB)\n\u001b[K     |████████████████████████████████| 36.9 MB 6.1 MB/s \n\u001b[?25hInstalling collected packages: av\nSuccessfully installed av-8.0.2\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nCollecting pims\n  Downloading PIMS-0.5.tar.gz (85 kB)\n\u001b[K     |████████████████████████████████| 85 kB 6.8 MB/s \n\u001b[?25hCollecting slicerator>=0.9.8\n  Downloading slicerator-1.0.0-py3-none-any.whl (9.3 kB)\nRequirement already satisfied: six>=1.8 in /opt/venv/lib/python3.7/site-packages (from pims) (1.15.0)\nRequirement already satisfied: numpy>=1.7 in /opt/venv/lib/python3.7/site-packages (from pims) (1.19.2)\nBuilding wheels for collected packages: pims\n  Building wheel for pims (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pims: filename=PIMS-0.5-py3-none-any.whl size=84326 sha256=1e6477b8dc6581740308e4089971501b205a8f8cbed720fe145b67b2e1bdfda7\n  Stored in directory: /home/jovyan/.cache/pip/wheels/75/02/a9/86571c38081ba4c1832eb95430b5d588dfa15a738e2a603737\nSuccessfully built pims\nInstalling collected packages: slicerator, pims\nSuccessfully installed pims-0.5 slicerator-1.0.0\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: pillow in /opt/venv/lib/python3.7/site-packages (7.2.0)\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nCollecting plotly\n  Downloading plotly-4.12.0-py2.py3-none-any.whl (13.1 MB)\n\u001b[K     |████████████████████████████████| 13.1 MB 15.5 MB/s \n\u001b[?25hRequirement already satisfied: six in /opt/venv/lib/python3.7/site-packages (from plotly) (1.15.0)\nCollecting retrying>=1.3.3\n  Downloading retrying-1.3.3.tar.gz (10 kB)\nBuilding wheels for collected packages: retrying\n  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=bce96651195c0783272c293f917efc4d9d26d86828fd20c5578b276f65b406ba\n  Stored in directory: /home/jovyan/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\nSuccessfully built retrying\nInstalling collected packages: retrying, plotly\nSuccessfully installed plotly-4.12.0 retrying-1.3.3\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n/opt/venv/lib/python3.7/site-packages/pims/image_reader.py:26: RuntimeWarning: PIMS image_reader.py could not find scikit-image. Falling back to matplotlib's imread(), which uses floats instead of integers. This may break your scripts. \n(To ignore this warning, include the line \"warnings.simplefilter(\"ignore\", RuntimeWarning)\" in your script.)\n  warnings.warn(RuntimeWarning(ski_preferred))\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-1c4509f9-a2cc-478b-b420-fbf3064ab6f8","output_cleared":false,"source_hash":"e236cf0a","execution_millis":1,"execution_start":1604441060894},"source":"## Use the following code for indexing image frame in the video.\n## Needed it because the calib0**.png images didnt have two boards in the images\n# v = pims.Video('./resources_unzipped/shadow.MOV')\n\n# for num, i in enumerate(v[:20]):\n#     im = Image.fromarray(v[num])\n#     im.save(f'./resources_unzipped/two_boards/frame{num}.png')\n    \n\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00003-52a18a5d-2c18-48b8-9ec2-783818b20046","output_cleared":false,"source_hash":"d5833c8c","execution_millis":383,"execution_start":1604441061331},"source":"v = pims.Video('./resources_unzipped/shadow2.MOV')\ntest_img = v[5]\nprint(test_img.shape)","execution_count":null,"outputs":[{"name":"stdout","text":"(1080, 1920, 3)\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00005-6d8bba7a-a14d-41c1-8026-f3d44764c393","output_cleared":false,"source_hash":"654f60ba","execution_millis":0,"execution_start":1604441065684},"source":"def detect_aprilboard_v2(img, board, apriltag_detector):\n    # Usage:  imgpoints, objpoints, tag_ids = detect_aprilboard(img,board,AT_detector)\n    #\n    # Input: \n    #   image -- grayscale image\n    #   board -- at_coarseboard or at_fineboard (list of dictionaries)\n    #   AT_detector -- AprilTag Detector parameters\n    #\n    # Returns: \n    #   imgpoints -- Nx2 numpy array of (x,y) image coords\n    #   objpoints -- Nx3 numpy array of (X,Y,Z=0) board coordinates (in inches)\n    #   tag_ids -- Nx1 list of tag IDs\n    \n    imgpoints=[]\n    objpoints=[]\n    tagIDs=[]\n    \n    # detect april tags\n    imgtags = apriltag_detector.detect(img, \n                                    estimate_tag_pose=False, \n                                    camera_params=None, \n                                    tag_size=None)\n\n    if len(imgtags):\n        # collect image coordinates of tag centers\n        # imgpoints = np.vstack([ sub.center for sub in tags ])\n\n        # list of all tag_id's that are in board\n        brdtagIDs = [ sub['tag_id'] for sub in board ]\n\n        # list of all detected tag_id's that are in image\n        imgtagIDs = [ sub.tag_id for sub in imgtags ]\n\n        # list of all tag_id's that are in both\n        tagIDs = list(set(brdtagIDs).intersection(imgtagIDs))\n        \n        if len(tagIDs):\n            # all board list-elements that contain one of the common tag_ids\n            objs=list(filter(lambda tagnum: tagnum['tag_id'] in tagIDs, board))\n            \n            # their centers\n            objpoints = np.vstack([ sub['center'] for sub in objs ])\n    \n            # all image list-elements that contain one of the detected tag_ids\n            imgs=list(filter(lambda tagnum: tagnum.tag_id in tagIDs, imgtags))    \n            \n            # their centers\n            imgpoints = np.vstack([ sub.center for sub in imgs ])\n        \n    return imgpoints, objpoints, tagIDs","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00006-cd7b35f6-b68f-4352-8b15-719b2e7a4d97","output_cleared":false,"source_hash":"b351e6b1","execution_start":1604075440171,"execution_millis":2},"source":"def add_camera(h,w,camera,raysize,figobj):\n# Add tetrahedral camera to pyplot figure\n# h,w:      height and width of image in pixels\n# camera:   3x4 camera matrix\n# raysize:  length of tetrahedral edges (in world units)\n# fig:      pyplot figure object\n#\n# Returns: 1\n#\n# Uses anatomy of camera matrices from Hartley and Zisserman Chapter 6\n\n    # normalize camera such that bottom-left three-vector \n    #   corresponds to unit-length principal ray in front of camera (HZ Section 6.2.3)\n    camera=camera*np.sign(np.linalg.det(camera[:,0:3]))/np.linalg.norm(camera[2,0:3])\n    \n    # Compute camera center (null vector of P), because Camera center is where every ray meets \n    _, _, v = np.linalg.svd(camera)\n    C = np.transpose(v[-1,0:3]) / v[-1,3]\n\n    # Back-project image corners to unit-length 3D ray segments:\n    S = np.array([[0, 0, 1],       # homog image coords if top left pixel\n                  [0, h-1, 1],     # bottom left \n                  [w-1, h-1, 1],   # bottom right\n                  [w, 0, 1]])      # top right\n    \n    #   HZ equation (6.14): compute one 3D point along each ray\n    X = np.transpose(np.linalg.lstsq(\n        camera[:,0:3], \n        np.transpose(S)-np.expand_dims(camera[:,3],axis=1), \n        rcond=None)[0])\n    \n    #   unit-vectors from camera center to each 3D point\n    V = X - np.tile(C, (4, 1))\n    V = V / np.linalg.norm(V, ord=2, axis=1, keepdims=True)\n    \n    # make sure these vectors point forwards from the camera instead of backwards\n    V = V*np.expand_dims(np.sign(np.sum(V * np.tile(camera[2,0:3],(4, 1)), axis=1)),axis=1)\n    \n    #   desired ray segments that are length raysize in these directions \n    V = np.tile(C, (4, 1)) + raysize * V\n    \n    # append the camera center itself to complete the four tetrahedral vertices\n    V=np.vstack([C,V])\n\n    # add camera center to figure\n    figobj.add_trace(go.Scatter3d(\n        x=[C[0]], \n        y=[C[1]],\n        z=[C[2]],\n        mode='markers',\n        marker=dict(\n            size=3,\n            color='#ff7f0e'\n        )\n    )\n                    )\n\n\n    # add tetrahedron to figure\n    figobj.add_trace(go.Mesh3d(\n        # vertices of tetrahedron\n        x=V[:,0],\n        y=V[:,1],\n        z=V[:,2],\n\n        # i, j and k give the vertices of triangles\n        i=[0, 0, 0, 0],\n        j=[1, 2, 3, 4],\n        k=[2, 3, 4, 1],\n        opacity=0.5,\n        color='#ff7f0e'\n    ))\n   \n    return 1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00007-45205312-d4e6-4b51-89f6-6a7e4f27e0fc","output_cleared":false,"source_hash":"f74e360b","execution_start":1604076632059,"execution_millis":0},"source":"# Convert from Nxm inhomogeneous to Nx(m+1) homogeneous coordinates\ndef in2hom(X):\n    return np.concatenate([X, np.ones((X.shape[0], 1), dtype=np.float32)], axis=1)\n\n# Convert from Nxm homogeneous to Nx(m-1) inhomogeneous coordinates\ndef hom2in(X):\n    return X[:, :-1] / X[:, -1:]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-1eee0c65-38b4-4d66-97fd-2aebd8524209","output_cleared":false,"source_hash":"10272b51","execution_millis":42,"execution_start":1604076254673},"source":"def computeTwoPlanes(calMatrix, distCoeffs, two_aprilboards_img, april_pkl='./resources_unzipped/AprilBoards.pickle', verify=False):\n    \"\"\"\n    Input:\n\n    calMatrix: from Arnav's calibrateCamera\n    distCoeffs: from Arnav's calibrateCamera\n    two_aprilboards_img : 3-color channeled numpy array img that contains two types of boards\n    april_pkl: the april pickle file given in class (applied universally for all the april fine & coarse boards)\n\n    \"\"\"    \n    print(\"RUN\")\n    two_aprilboards_img = cv2.cvtColor(two_aprilboards_img, cv2.COLOR_RGB2GRAY)\n\n    #initialize at_detector\n    # set up april tag detector (I use default parameters; seems to be OK)\n\n    data = pickle.load(open(april_pkl, 'rb'))\n    at_coarseboard = data['at_coarseboard']\n    at_fineboard = data['at_fineboard']\n    at_detector = Detector(families='tag36h11',\n                        nthreads=1,\n                        quad_decimate=1.0,\n                        quad_sigma=0.0,\n                        refine_edges=1,\n                        decode_sharpening=0.25,\n                        debug=0)\n\n    # detect apriltags and report number of detections. Do this for both boards (fine and coarse).\n    imgpoints_fine, objpoints_fine, tagIDs_fine = detect_aprilboard_v2(\n        two_aprilboards_img,\n        at_fineboard,\n        at_detector)\n    imgpoints_coarse, objpoints_coarse, tagIDs_coarse = detect_aprilboard_v2(\n        two_aprilboards_img,\n        at_coarseboard,\n        at_detector)\n\n    # compute normalized image coordinates (equivalent to K^{-1}*x)\n    # 즉, imgpoints_fine 이라는 이미지 내의 좌표로 표시된 각 QR 코드의 중심부 좌표를 \n    #카메라 메트릭스(카메라-to-이미지 principal위치(0,0 이 이미지 중앙, 카메라 렌즈 정중앙에 맞게), focal length)\n    #와 굴절율을 고려해서 다시 재조정.\n    imgpts_fine_norm = cv2.undistortPoints(imgpoints_fine, calMatrix, distCoeffs)\n    imgpts_coarse_norm = cv2.undistortPoints(imgpoints_coarse, calMatrix, distCoeffs)\n\n    # homographies from each board to normalized image pts\n    H_fine,_ = cv2.findHomography(objpoints_fine[:,:2],imgpts_fine_norm)\n    H_fine = 2*H_fine/(\n                    np.linalg.norm(H_fine[:,0]) + np.linalg.norm(H_fine[:,1])\n                    )\n    # 아래의 np.atleast_2d(np.cross(H_fine[:,0],H_fine[:,1])).T 부분은 R = [r1, r2, r1 x r2] 에서 r1 x r2를 구현한 것이다.\n    R_fine = np.hstack((H_fine[:,:2],np.atleast_2d(np.cross(H_fine[:,0],H_fine[:,1])).T))\n    # cv2.Rodrigues: https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga61585db663d9da06b68e70cfbf6a1eac\n    # Converts a rotation matrix to a rotation vector or vice versa.\n    rvec_fine,_ = cv2.Rodrigues(R_fine)\n    R_fine,_ = cv2.Rodrigues(rvec_fine)\n    tvec_fine=H_fine[:,2]\n\n    H_coarse,_ = cv2.findHomography(objpoints_coarse[:,:2],imgpts_coarse_norm)\n    # extract rotation and translation from homography: coarseboard\n    H_coarse = 2*H_coarse/(np.linalg.norm(H_coarse[:,0]) + np.linalg.norm(H_coarse[:,1]))\n    R_coarse = np.hstack((H_coarse[:,:2],np.atleast_2d(np.cross(H_coarse[:,0],H_coarse[:,1])).T))\n    rvec_coarse,_ = cv2.Rodrigues(R_coarse)\n    R_coarse,_ = cv2.Rodrigues(rvec_coarse)\n    tvec_coarse=H_coarse[:,2]\n\n    \n    #LEFT TO DO 1: Get Camera coordinat system 4-vector\n\n    # Apply G^(-T) to Pi_P\n    # Pi_c = G^(-T) Pi_P ==> Let Pi_P  be the plane normal (0, 0, 1, 0)\n\n    # We took the Presession 8 quiz and know that  Pi_c can just be calculated (r3, -r3^Tt)\n    if verify:\n        print(\"R fine:\")\n        print(R_fine)\n\n        print(\"R coarse\")\n        print(R_coarse)\n\n    # In our case, plane_v is the fine board\n    # plane_h is the coarse board\n\n    #Output: plane_h, plane_v -- Two homogeneous 4-vectors corresponding to planes (\\Pi_v, \\Pi_h) in the camera-centered coordinate system.\n    r3_coarse = R_coarse[:,2]\n    plane_h = np.hstack([r3_coarse, -r3_coarse.T @ tvec_coarse])\n\n    #plane_v calculation\n    r3_fine = R_fine[:,2]\n    plane_v = np.hstack([r3_fine, -r3_fine.T @ tvec_fine])\n    print(\"printing plane_h\")\n    print(plane_h)\n\n    print(\"printing plane_v\")\n    print(plane_v)\n    #TODO 2: test code for this function\n\n    print(verify)\n    if verify:\n        plt.imshow(two_aprilboards_img, cmap=\"gray\")\n        plt.axis('off')\n\n        #normalized_pH = plane_h / np.linalg.norm(plane_h)\n        #normalized_pV = plane_v / np.linalg.norm(plane_v)\n        \n        pH_3vec = (plane_h / plane_h[3])[:3]\n        pV_3vec = (plane_v / plane_v[3])[:3]\n        print(\"pH_3vec:\")\n        print(pH_3vec)\n\n        plane_intersection = np.cross(pH_3vec, pV_3vec)\n        plane_inter_3vec = plane_intersection / plane_intersection[2]\n        print(\"plane_inter_3vec:\")\n        print(plane_inter_3vec) ## This is normalized point\n\n        # Normalized @\n        axes3d = np.float32([[0,0,0], [3,0,0], [0,3,0], [0,0,3]]).reshape(-1,3)\n        \n        # rotate/translate axes3d object to fineplane origin and project into camera \n        imaxes_fine,_  = cv2.projectPoints(axes3d, rvec_fine, tvec_fine, calMatrix, distCoeffs)\n\n        # eliminate the singleton dimension (quirk of openCV format, a bit annoying)\n        imaxes_fine = np.squeeze(imaxes_fine) \n\n        plt.plot(imaxes_fine[[0,1],0], imaxes_fine[[0,1],1], color='#d62728', linewidth=6)\n        plt.plot(imaxes_fine[[0,2],0], imaxes_fine[[0,2],1], color='#2ca02c', linewidth=6)\n        plt.plot(imaxes_fine[[0,3],0], imaxes_fine[[0,3],1], color='#1f77b4', linewidth=6)\n\n        # rotate/translate axes3d object to coarseplane origin and project into camera \n        imaxes_coarse,_  = cv2.projectPoints(axes3d, rvec_coarse, tvec_coarse, calMatrix, distCoeffs)\n\n        # eliminate the singleton dimension (quirk of openCV format, a bit annoying)\n        imaxes_coarse=np.squeeze(imaxes_coarse)\n\n        plt.plot(imaxes_coarse[[0,1],0], imaxes_coarse[[0,1],1], color='#d62728', linewidth=6)\n        plt.plot(imaxes_coarse[[0,2],0], imaxes_coarse[[0,2],1], color='#2ca02c', linewidth=6)\n        plt.plot(imaxes_coarse[[0,3],0], imaxes_coarse[[0,3],1], color='#1f77b4', linewidth=6)\n        plt.show()\n        print(\"now vis1\")\n        # Visualization 1: \n        #   Back-project rays through image points (detected tags) and compute\n        #   intersection of these rays with the corresponding plane. Plot the\n        #   3D intersection points and see if they look right.\n\n        # compute normalized image coordinates (equivalent to K^{-1}*x)\n        # Normalized coordinates, when appended with 1 at the end, are the back-projected \n        # ray of point in the camera coordinate system. ( x, y, 1) is the 3d-space point \n\n        imgpts_fine_norm = cv2.undistortPoints(imgpoints_fine, calMatrix, distCoeffs)\n        imgpts_fine_norm = np.squeeze(imgpts_fine_norm)  # remove extraneous size-1 dimension from openCV (annoying)\n\n        imgpts_coarse_norm = cv2.undistortPoints(imgpoints_coarse, calMatrix, distCoeffs)\n        imgpts_coarse_norm = np.squeeze(imgpts_coarse_norm)  # remove extraneous size-1 dimension from openCV (annoying)\n\n        # back-projections are homogeneous versions of these \n        # backproj is the backprojected ray to the plane \n        backproj_fine = in2hom(imgpts_fine_norm)\n        print(backproj_fine)\n        backproj_coarse = in2hom(imgpts_coarse_norm)\n\n        # WORK HERE: \n        # Replace the following two lines to:\n        #   1. Compute Nx3 array (intersect_fine) of 3D points that correspond to \n        #      intersections of backproj_fine with plane_fine\n        #   2. Compute Nx3 array (intersect_coarse) of 3D points that correspond to \n        #      intersections of backproj_coarse with plane_coarse\n\n        intersect_fine_lambda = -plane_v[3] / np.dot(backproj_fine, plane_v[:3])\n        intersect_fine = np.expand_dims(intersect_fine_lambda, axis=1) * backproj_fine\n\n        intersect_coarse_lambda = -plane_h[3] / np.dot(backproj_coarse, plane_h[:3])\n        intersect_coarse = np.expand_dims(intersect_coarse_lambda, axis=1) * backproj_coarse\n\n        # WORK HERE: \n        # Replace the following line to properly define the 3x4 camera matrix P based on \n        # the 3x3 matrix calMatrix (for input to the add_camera() function)\n        P = np.hstack((calMatrix, np.zeros((3,1))))\n        # K = 3x3 , P = 3x4.( Since everything is with respect to the camera coordinate system),\n\n        # P = K[I|0]  ==> So, no rotation \n\n        # create figure\n        print(\"creating figure!\")\n        fig = go.Figure()\n\n        # add 3D box corners (as done above)\n        fig.add_trace(go.Scatter3d(x=intersect_fine[:,0], \n                                y=intersect_fine[:,1],\n                                z=intersect_fine[:,2],\n                                mode='markers',\n                                marker=dict(\n                                    size=2,\n                                    color='#1f77b4'\n                                )\n                                ))\n\n        # add 3D box corners (as done above)\n        fig.add_trace(go.Scatter3d(x=intersect_coarse[:,0], \n                                y=intersect_coarse[:,1],\n                                z=intersect_coarse[:,2],\n                                mode='markers',\n                                marker=dict(\n                                    size=2,\n                                    color='#2ca02c'\n                                )\n                                ))\n\n\n        # add camera\n        h,w=two_aprilboards_img.shape\n        add_camera(h,w,P,1,fig)\n\n        # adjust aspect ratio and initial viewing direction\n        fig.update_layout(scene_aspectmode='manual',\n                        scene_aspectratio=dict(x=1, y=2, z=3),\n                        showlegend=False,\n                        scene_camera=dict(\n                            up=dict(x=0, y=-1, z=0),\n                            center=dict(x=0, y=0, z=0),\n                            eye=dict(x=-1, y=-1, z=-5)\n                        )\n                        )\n\n        fig.show()\n\n\n        \n\n    return plane_h, plane_v \n\n\n\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00009-5234e7e8-950f-49c6-8aef-b80d1f8aec6d"},"source":"def draw_twoPlanes():\n    print(verify)\n    if verify:\n        plt.imshow(two_aprilboards_img, cmap=\"gray\")\n        plt.axis('off')\n\n        #normalized_pH = plane_h / np.linalg.norm(plane_h)\n        #normalized_pV = plane_v / np.linalg.norm(plane_v)\n        \n        pH_3vec = (plane_h / plane_h[3])[:3]\n        pV_3vec = (plane_v / plane_v[3])[:3]\n        print(\"pH_3vec:\")\n        print(pH_3vec)\n\n        plane_intersection = np.cross(pH_3vec, pV_3vec)\n        plane_inter_3vec = plane_intersection / plane_intersection[2]\n        print(\"plane_inter_3vec:\")\n        print(plane_inter_3vec) ## This is normalized point\n\n        # Normalized @\n        axes3d = np.float32([[0,0,0], [3,0,0], [0,3,0], [0,0,3]]).reshape(-1,3)\n        \n        # rotate/translate axes3d object to fineplane origin and project into camera \n        imaxes_fine,_  = cv2.projectPoints(axes3d, rvec_fine, tvec_fine, calMatrix, distCoeffs)\n\n        # eliminate the singleton dimension (quirk of openCV format, a bit annoying)\n        imaxes_fine = np.squeeze(imaxes_fine) \n\n        plt.plot(imaxes_fine[[0,1],0], imaxes_fine[[0,1],1], color='#d62728', linewidth=6)\n        plt.plot(imaxes_fine[[0,2],0], imaxes_fine[[0,2],1], color='#2ca02c', linewidth=6)\n        plt.plot(imaxes_fine[[0,3],0], imaxes_fine[[0,3],1], color='#1f77b4', linewidth=6)\n\n        # rotate/translate axes3d object to coarseplane origin and project into camera \n        imaxes_coarse,_  = cv2.projectPoints(axes3d, rvec_coarse, tvec_coarse, calMatrix, distCoeffs)\n\n        # eliminate the singleton dimension (quirk of openCV format, a bit annoying)\n        imaxes_coarse=np.squeeze(imaxes_coarse)\n\n        plt.plot(imaxes_coarse[[0,1],0], imaxes_coarse[[0,1],1], color='#d62728', linewidth=6)\n        plt.plot(imaxes_coarse[[0,2],0], imaxes_coarse[[0,2],1], color='#2ca02c', linewidth=6)\n        plt.plot(imaxes_coarse[[0,3],0], imaxes_coarse[[0,3],1], color='#1f77b4', linewidth=6)\n        plt.show()\n        print(\"now vis1\")\n        # Visualization 1: \n        #   Back-project rays through image points (detected tags) and compute\n        #   intersection of these rays with the corresponding plane. Plot the\n        #   3D intersection points and see if they look right.\n\n        # compute normalized image coordinates (equivalent to K^{-1}*x)\n        # Normalized coordinates, when appended with 1 at the end, are the back-projected \n        # ray of point in the camera coordinate system. ( x, y, 1) is the 3d-space point \n\n        imgpts_fine_norm = cv2.undistortPoints(imgpoints_fine, calMatrix, distCoeffs)\n        imgpts_fine_norm = np.squeeze(imgpts_fine_norm)  # remove extraneous size-1 dimension from openCV (annoying)\n\n        imgpts_coarse_norm = cv2.undistortPoints(imgpoints_coarse, calMatrix, distCoeffs)\n        imgpts_coarse_norm = np.squeeze(imgpts_coarse_norm)  # remove extraneous size-1 dimension from openCV (annoying)\n\n        # back-projections are homogeneous versions of these \n        # backproj is the backprojected ray to the plane \n        backproj_fine = in2hom(imgpts_fine_norm)\n        print(backproj_fine)\n        backproj_coarse = in2hom(imgpts_coarse_norm)\n\n        # WORK HERE: \n        # Replace the following two lines to:\n        #   1. Compute Nx3 array (intersect_fine) of 3D points that correspond to \n        #      intersections of backproj_fine with plane_fine\n        #   2. Compute Nx3 array (intersect_coarse) of 3D points that correspond to \n        #      intersections of backproj_coarse with plane_coarse\n\n        intersect_fine_lambda = -plane_v[3] / np.dot(backproj_fine, plane_v[:3])\n        intersect_fine = np.expand_dims(intersect_fine_lambda, axis=1) * backproj_fine\n\n        intersect_coarse_lambda = -plane_h[3] / np.dot(backproj_coarse, plane_h[:3])\n        intersect_coarse = np.expand_dims(intersect_coarse_lambda, axis=1) * backproj_coarse\n\n        # WORK HERE: \n        # Replace the following line to properly define the 3x4 camera matrix P based on \n        # the 3x3 matrix calMatrix (for input to the add_camera() function)\n        P = np.hstack((calMatrix, np.zeros((3,1))))\n        # K = 3x3 , P = 3x4.( Since everything is with respect to the camera coordinate system),\n\n        # P = K[I|0]  ==> So, no rotation \n\n        # create figure\n        print(\"creating figure!\")\n        fig = go.Figure()\n\n        # add 3D box corners (as done above)\n        fig.add_trace(go.Scatter3d(x=intersect_fine[:,0], \n                                y=intersect_fine[:,1],\n                                z=intersect_fine[:,2],\n                                mode='markers',\n                                marker=dict(\n                                    size=2,\n                                    color='#1f77b4'\n                                )\n                                ))\n\n        # add 3D box corners (as done above)\n        fig.add_trace(go.Scatter3d(x=intersect_coarse[:,0], \n                                y=intersect_coarse[:,1],\n                                z=intersect_coarse[:,2],\n                                mode='markers',\n                                marker=dict(\n                                    size=2,\n                                    color='#2ca02c'\n                                )\n                                ))\n\n\n        # add camera\n        h,w=two_aprilboards_img.shape\n        add_camera(h,w,P,1,fig)\n\n        # adjust aspect ratio and initial viewing direction\n        fig.update_layout(scene_aspectmode='manual',\n                        scene_aspectratio=dict(x=1, y=2, z=3),\n                        showlegend=False,\n                        scene_camera=dict(\n                            up=dict(x=0, y=-1, z=0),\n                            center=dict(x=0, y=0, z=0),\n                            eye=dict(x=-1, y=-1, z=-5)\n                        )\n                        )\n\n        fig.show()\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00006-9897f58b-93e2-4b42-b1f1-b541154bb93e","output_cleared":false,"source_hash":"37cf5183","execution_millis":586},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"91301e72-2826-4ab1-a9fc-2346e36be1aa","deepnote_execution_queue":[]}}